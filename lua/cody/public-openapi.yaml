# Code generated by TypeSpec - DO NOT EDIT
openapi: 3.0.0
info:
  title: Sourcegraph
  version: Latest
tags: []
paths:
  /.api/cody/context:
    post:
      operationId: CodyService_context
      description: Send a natural language query with a list of repositories, and Cody locates related code examples from those repos.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CodyContextResponse'
              example:
                results:
                  - blob:
                      url: /github.com/sourcegraph/cody@fedd5d4c4af5c30b9eb661465b86155fe550cd60/-/blob/agent/README.md
                      commit:
                        oid: fedd5d4c4af5c30b9eb661465b86155fe550cd60
                      path: agent/README.md
                      repository:
                        id: UmVwb3NpdG9yeTo2MTMyNTMyOA==
                        name: github.com/sourcegraph/cody
                    startLine: 0
                    endLine: 3
                    chunkContent: |-
                      # Cody Agent
                      The `@sourcegraph/cody-agent` package implements a JSON-RPC server to interact
                      with Cody via stdout/stdin. This package is intended to be used by
                      non-ECMAScript clients such as the JetBrains and NeoVim plugins.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CodyContextRequest'
            example:
              query: what is the agent?
              repos:
                - name: github.com/sourcegraph/cody
              textResultsCount: 10
              codeResultsCount: 5
              filePatterns:
                - ^agent/.*
  /.api/llm/chat/completions:
    post:
      operationId: LLMService_chatCompletions
      description: Send a structured list of input messages with text and/or image content, and the model will generate the next message in the conversation.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
              example:
                id: chat-UUID
                created: 1727692163829
                model: anthropic::2023-06-01::claude-3.5-sonnet
                object: object
                choices:
                  - index: 0
                    finish_reason: stop
                    message:
                      role: assistant
                      content: URIs identify, URLs locate
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
            example:
              model: anthropic::2023-06-01::claude-3.5-sonnet
              max_tokens: 2000
              messages:
                - role: user
                  content: what is the difference between URI and URL?
  /.api/llm/chat/completions/stream:
    post:
      operationId: LLMService_streamChatCompletions
      description: |-
        This endpoint does not exist. It's only used to document the shape
        of `/.api/llm/chat/completions` when `"stream": true`.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionsStreamEvents'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
  /.api/llm/models:
    get:
      operationId: LLMService_list
      description: Lists the currently available models, and provides basic information about each one such as the owner and availability.
      parameters: []
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OAIListModelsResponse'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
  /.api/llm/models/{modelId}:
    get:
      operationId: LLMService_retrieveModel
      description: Retrieves a model instance, providing basic information about the model such as the owner and permissioning.
      parameters:
        - name: modelId
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: The request has succeeded.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OAIModel'
        default:
          description: An unexpected error response.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
security:
  - SourcegraphTokenAuth: []
components:
  schemas:
    AssistantToolsFunction:
      type: object
      required:
        - type
        - function
      properties:
        type:
          type: string
          enum:
            - function
        function:
          $ref: '#/components/schemas/FunctionObject'
    BlobInfo:
      type: object
      required:
        - path
        - repository
        - commit
        - url
      properties:
        path:
          type: string
          description: The file path to the blob.
        repository:
          allOf:
            - $ref: '#/components/schemas/RepositoryInfo'
          description: Information about the repository containing the blob.
        commit:
          allOf:
            - $ref: '#/components/schemas/CommitInfo'
          description: Information about the commit containing the blob.
        url:
          type: string
          description: A canonical URL to the blob, relative to the Sourcegraph instance.
      description: Information about a blob.
    ChatCompletionChoice:
      type: object
      required:
        - index
        - message
      properties:
        finish_reason:
          type: string
          enum:
            - stop
            - length
          nullable: true
          description: The reason why the completion stopped.
        index:
          type: integer
          format: int32
          description: The index of the completion choice. Always 0 at this moment.
        message:
          allOf:
            - $ref: '#/components/schemas/ChatCompletionResponseMessage'
          description: The message generated by the completion.
        logprobs:
          type: object
          allOf:
            - $ref: '#/components/schemas/ChatCompletionLogprobs'
          nullable: true
    ChatCompletionChunkChoice:
      type: object
      required:
        - delta
        - index
      properties:
        delta:
          allOf:
            - $ref: '#/components/schemas/ChatCompletionStreamResponseDelta'
          description: The partial message data for this choice
        logprobs:
          type: object
          allOf:
            - $ref: '#/components/schemas/ChatCompletionLogprobs'
          nullable: true
          description: Unsupported.
        finish_reason:
          type: string
          enum:
            - stop
            - length
            - tool_calls
            - content_filter
            - function_call
          nullable: true
          description: |-
            The reason the model stopped generating tokens. This will be
            `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            `content_filter` if content was omitted due to a flag from our content filters,
            `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
        index:
          type: integer
          format: int32
          description: The index of the choice in the list of choices.
      description: A choice in a chat completion chunk response
    ChatCompletionLogprobs:
      type: object
      properties:
        content:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionTokenLogprob'
          description: Unsupported.
    ChatCompletionMessageToolCallChunk:
      type: object
      required:
        - index
        - id
        - type
        - function
      properties:
        index:
          type: integer
          format: int32
          description: The index of the tool call.
        id:
          type: string
          description: The ID of the tool call.
        type:
          type: string
          enum:
            - function
          description: The type of the tool. Currently, only `function` is supported.
        function:
          allOf:
            - $ref: '#/components/schemas/ToolCallFunction'
          description: The function that the model called.
    ChatCompletionRequestMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum:
            - user
            - assistant
            - system
          description: |-
            The role of the message sender.

            The "system" role is unsupported at this moment.
        content:
          anyOf:
            - type: string
            - type: array
              items:
                $ref: '#/components/schemas/MessageContentPart'
          description: The content of the message.
    ChatCompletionResponseMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum:
            - user
            - assistant
          description: The role of the message sender.
        content:
          type: string
          nullable: true
          description: |-
            The content of the generated message.

            Can be null when tools are used.
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolCall'
          nullable: true
    ChatCompletionStreamOptions:
      type: object
      properties:
        include_usage:
          type: boolean
          nullable: true
          description: Unsupported.
    ChatCompletionStreamResponseDelta:
      type: object
      properties:
        content:
          type: string
          nullable: true
          description: The contents of the chunk message.
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionMessageToolCallChunk'
          nullable: true
          description: Array of tool calls in this delta
        role:
          type: string
          enum:
            - system
            - user
            - assistant
            - tool
          nullable: true
          description: The role of the author of this message.
        refusal:
          type: string
          nullable: true
          description: The refusal message generated by the model.
    ChatCompletionTokenLogprob:
      type: object
      required:
        - token
        - logprob
        - bytes
        - top_logprobs
      properties:
        token:
          type: string
          description: Unsupported.
        logprob:
          type: number
          format: double
          description: Unsupported.
        bytes:
          type: array
          items:
            type: integer
            format: int32
          description: Unsupported.
        top_logprobs:
          type: object
          required:
            - token
            - logprob
            - bytes
          properties:
            token:
              type: string
              description: Unsupported.
            logprob:
              type: number
              format: double
              description: Unsupported.
            bytes:
              type: array
              items:
                type: integer
                format: int32
              description: Unsupported.
          description: Unsupported.
    CodyContextRequest:
      type: object
      required:
        - query
      properties:
        repos:
          type: array
          items:
            $ref: '#/components/schemas/RepoSpec'
          description: The list of repos to search through.
        query:
          type: string
          description: The natural language query to find relevant context from the provided list of repos.
        codeResultsCount:
          type: integer
          format: int32
          minimum: 0
          maximum: 100
          description: 'The number of results to return from source code (example: Python or TypeScript).'
          default: 15
        textResultsCount:
          type: integer
          format: int32
          minimum: 0
          maximum: 100
          description: The number of results to return from text sources like Markdown.
          default: 5
        filePatterns:
          type: array
          items:
            type: string
          description: |-
            An optional list of file patterns used to filter the results. The
            patterns are regex strings. For a file chunk to be returned a context
            result, the path must match at least one of these patterns.
        version:
          type: string
          enum:
            - '1.0'
            - '2.0'
          description: |-
            The version number of the context API

            Valid versions:
            - "1.0": The old context API (default).
            - "2.0": The new context API.
          default: '1.0'
    CodyContextResponse:
      type: object
      required:
        - results
      properties:
        results:
          type: array
          items:
            $ref: '#/components/schemas/FileChunkContext'
          description: The list of file chunks that are relevant to the provided natural language query.
      description: The response to a Cody context request.
    CommitInfo:
      type: object
      required:
        - oid
      properties:
        oid:
          type: string
          description: The commit hash (aka. OID).
      description: Information about the commit.
    CompletionUsage:
      type: object
      required:
        - completion_tokens
        - prompt_tokens
        - total_tokens
      properties:
        completion_tokens:
          type: integer
          format: int32
          description: Number of tokens in the generated completion.
        prompt_tokens:
          type: integer
          format: int32
          description: Number of tokens in the prompt.
        total_tokens:
          type: integer
          format: int32
          description: Total number of tokens used in the request (prompt + completion).
      description: Usage statistics for the completion request.
    CreateChatCompletionRequest:
      type: object
      required:
        - model
      properties:
        messages:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionRequestMessage'
          description: A list of messages to start the thread with.
        model:
          type: string
          description: |-
            A model name using the syntax `${ProviderID}::${APIVersionID}::${ModelID}`:
            - ProviderID: lowercase name of the LLM provider. Example: `"anthropic"` in
            `"anthropic::2023-06-01::claude-3.5-sonnet"`.
            - APIVersionID: the upstream LLM provider API version. Typically formatted as
            a date. Example, `"2024-02-01"` in `"openai::2024-02-01::gpt-4o"`.
            - ModelID: the name of the model. Example, `"mixtral-8x7b-instruct"` in
            `"mistral::v1::mixtral-8x7b-instruct"`.

            Use `GET /.api/llm/models` to list available models.
        max_tokens:
          type: integer
          format: int32
          nullable: true
          maximum: 4000
          description: The maximum number of tokens that can be generated in the completion.
        temperature:
          type: number
          format: float
          nullable: true
          minimum: 0
          maximum: 1
          description: |-
            The sampling temperature. Higher values like 0.8 will make the output
            more random, while lower values like 0.2 will make it more focused and
            deterministic. If set to 0, the model will use log probability to
            automatically increase the temperature until certain thresholds are hit.
        top_p:
          type: number
          format: float
          nullable: true
          description: |-
            An alternative to sampling with temperature, called nucleus sampling,
            where the model considers the results of the tokens with top_p
            probability mass. So 0.1 means only the tokens comprising the top 10%
            probability mass are considered.

            We generally recommend altering this or temperature but not both.
        'n':
          type: integer
          format: int32
          nullable: true
          minimum: 1
          maximum: 1
          description: The number of completions to generate. Only one completion is supported.
        logit_bias:
          type: object
          additionalProperties:
            type: integer
            format: int32
          nullable: true
          description: Unsupported.
        logprobs:
          type: boolean
          nullable: true
          description: Unsupported.
        top_logprobs:
          type: integer
          format: int32
          nullable: true
          description: Unsupported.
        frequency_penalty:
          type: number
          format: double
          nullable: true
          description: Unsupported.
        presence_penalty:
          type: number
          format: double
          nullable: true
          description: Unsupported.
        response_format:
          type: string
          enum:
            - text
            - json_object
          nullable: true
          description: Only the "text" format is supported.
        seed:
          type: integer
          format: int64
          nullable: true
          description: Unsupported.
        service_tier:
          type: string
          nullable: true
          description: Unsupported.
        stop:
          anyOf:
            - type: string
            - type: array
              items:
                type: string
          nullable: true
          description: Unsupported.
        stream:
          type: boolean
          nullable: true
          description: Unsupported.
        stream_options:
          type: object
          allOf:
            - $ref: '#/components/schemas/ChatCompletionStreamOptions'
          nullable: true
          description: Unsupported.
        user:
          type: string
          nullable: true
          description: Unsupported.
        tools:
          type: array
          items:
            $ref: '#/components/schemas/AssistantToolsFunction'
          description: |-
            A list of tool enabled on the assistant. There can be a maximum of
            128 tools per assistant. Tools can only be of type `function`.
    CreateChatCompletionResponse:
      type: object
      required:
        - id
        - choices
        - created
        - model
        - object
      properties:
        id:
          type: string
          description: A unique ID for this completion response.
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionChoice'
          description: |-
            The list of completion choices. Always a single completion
            at this moment. The `n` parameter in the request is ignored.
        created:
          type: integer
          format: int64
          description: The Unix timestamp (in seconds) when the completion was created.
        model:
          type: string
          description: The model used to generate the completion.
        service_tier:
          type: string
          nullable: true
          description: Unsupported.
        system_fingerprint:
          type: string
          nullable: true
          description: Unsupported.
        object:
          type: string
          enum:
            - object
          description: The object type, which is always "object".
        usage:
          type: object
          allOf:
            - $ref: '#/components/schemas/CompletionUsage'
          nullable: true
          description: The number of used input and output tokens.
    CreateChatCompletionStreamResponse:
      type: object
      required:
        - id
        - object
        - created
        - model
        - choices
      properties:
        id:
          type: string
          description: A unique identifier for this chat completion.
        object:
          type: string
          enum:
            - chat.completion.chunk
          description: The object type, which is always 'chat.completion.chunk'
        created:
          type: integer
          format: int64
          description: The Unix timestamp (in seconds) of when the chat completion was created.
        model:
          type: string
          description: The model used for the chat completion.
        system_fingerprint:
          type: string
          nullable: true
          description: The system fingerprint of the model used.
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionChunkChoice'
          description: An array of chat completion choices. Can contain one or more elements.
        usage:
          type: object
          allOf:
            - $ref: '#/components/schemas/CompletionUsage'
          nullable: true
          description: Usage statistics for the request. Only present in the last chunk if include_usage is set to true.
      discriminator:
        propertyName: object
      description: The chat completion chunk object
    CreateChatCompletionsStreamEvents:
      type: object
      required:
        - data
      properties:
        data:
          $ref: '#/components/schemas/CreateChatCompletionStreamResponse'
    Error:
      type: object
      required:
        - type
        - message
      properties:
        type:
          type: string
          description: The error type.
        message:
          type: string
          description: The error message.
    FileChunkContext:
      type: object
      required:
        - blob
        - startLine
        - endLine
        - chunkContent
      properties:
        blob:
          allOf:
            - $ref: '#/components/schemas/BlobInfo'
          description: Information about the blob containing the file chunk.
        startLine:
          type: integer
          format: int32
          description: The start line number of the file chunk.
        endLine:
          type: integer
          format: int32
          description: The end line number of the file chunk.
        chunkContent:
          type: string
          description: The content of the file chunk that is relevant to the provided natural language query.
      description: A single file chunk from a Cody context response.
    FunctionObject:
      type: object
      required:
        - name
      properties:
        name:
          type: string
          minLength: 1
          maxLength: 64
          pattern: ^[a-zA-Z0-9_-]+$
          description: |-
            The name of the function to be called. Must be a-z, A-Z, 0-9, or
            contain underscores and dashes, with a maximum length of 64.
        description:
          type: string
          description: |-
            A description of what the function does, used by the model to
            choose when and how to call the function.
        strict:
          type: boolean
          nullable: true
          description: |-
            Whether to enable strict schema adherence when generating the
            function call. If set to true, the model will follow the exact
            schema defined in the `parameters` field. Only a subset of JSON
            Schema is supported when `strict` is `true`.
        parameters:
          type: object
          additionalProperties: {}
          description: |-
            The parameters the functions accepts, described as a JSON Schema object.
            See the guide for examples, and the JSON Schema reference for documentation
            about the format.

            Omitting `parameters` defines a function with an empty parameter list.
    MessageContentPart:
      type: object
      required:
        - type
        - text
      properties:
        type:
          type: string
          enum:
            - text
          description: The type of the message content part.
        text:
          type: string
          description: The text content of the message.
    OAIListModelsResponse:
      type: object
      required:
        - object
        - data
      properties:
        object:
          type: string
          enum:
            - list
          description: The object type, which is always "list".
        data:
          type: array
          items:
            $ref: '#/components/schemas/OAIModel'
          description: The list of models.
    OAIModel:
      type: object
      required:
        - id
        - object
        - created
        - owned_by
      properties:
        id:
          type: string
          description: The model identifier, which can be referenced in the API endpoints.
        object:
          type: string
          enum:
            - model
          description: The object type, which is always "model".
        created:
          type: integer
          format: int64
          description: The Unix timestamp (in seconds) when the model was created.
        owned_by:
          type: string
          description: The organization that owns the model.
      description: Describes an OpenAI model offering that can be used with the API.
    RepoSpec:
      type: object
      properties:
        name:
          type: string
          description: The name of the repository.
        id:
          type: string
          description: The ID of the repository.
      description: |-
        RepoSpec matches a repository either by name or ID.

        Exactly one of the properties must be defined. For example, the message
        `{id:"id", name:"name"}` is invalid because it declares both id and name.
    RepositoryInfo:
      type: object
      required:
        - id
        - name
      properties:
        id:
          type: string
          description: The repository ID, which is stable even if the repository name changes.
        name:
          type: string
          description: The repository name.
      description: Information about the repository.
    ToolCall:
      type: object
      required:
        - id
        - type
        - function
      properties:
        id:
          type: string
          description: The ID of the tool call.
        type:
          type: string
          enum:
            - function
          description: The type of the tool. Currently, only `function` is supported.
        function:
          allOf:
            - $ref: '#/components/schemas/ToolCallFunction'
          description: The function that the model called.
    ToolCallFunction:
      type: object
      required:
        - name
        - arguments
      properties:
        name:
          type: string
          description: The name of the function to call.
        arguments:
          type: string
          description: |-
            The arguments to call the function with, as generated by the model in JSON format.
            Note that the model does not always generate valid JSON, and may hallucinate parameters
            not defined by your function schema. Validate the arguments in your code before
            calling your function.
  securitySchemes:
    SourcegraphTokenAuth:
      type: apiKey
      in: header
      name: Authorization
      description: |-
        Authenticate to Sourcegraph APIs with the HTTP header "Authorization" using
        the following formatting:

        ```
        Authorization: token TOKEN_VALUE
        ```
        In most cases, a Sourcegraph access token looks like this `sgp_asdadakjaaaaaaabbbbbbssswwwwaaal2131kasdaakkkkkq21asdasaa`.

        In rare cases, you may encounter other kinds of token formats, which are documented in the table below.

        |                  Token Name                  |                                   Description                                    |            Type            |    Regular Expression     |                         |
        | -------------------------------------------- | -------------------------------------------------------------------------------- | -------------------------- | ------------------------- | ----------------------- |
        | Sourcegraph Access Token (v3)                | Token used to access the Sourcegraph GraphQL API                                 | User-generated             | `sgp_(?:[a-fA-F0-9]{16}\|local)_[a-fA-F0-9]{40}` |
        | Sourcegraph Access Token (v2, deprecated)    | Token used to access the Sourcegraph GraphQL API                                 | User-generated             | `sgp_[a-fA-F0-9]{40}`     |                         |
        | Sourcegraph Access Token (v1, deprecated)    | Token used to access the Sourcegraph GraphQL API                                 | User-generated             | `[a-fA-F0-9]{40}`         |                         |
        | Sourcegraph Dotcom User Gateway Access Token | Token used to grant sourcegraph.com users access to Cody                         | Backend (not user-visible) | `sgd_[a-fA-F0-9]{64}`     |                         |
        | Sourcegraph License Key Token                | Token used for product subscriptions, derived from a Sourcegraph license key     | Backend (not user-visible) | `slk_[a-fA-F0-9]{64}`     |                         |
        | Sourcegraph Enterprise subscription (aka "product subscription") Token       | Token used for Enterprise subscriptions, derived from a Sourcegraph license key | Backend (not user-visible) | `sgs_[a-fA-F0-9]{64}`     |                         |
